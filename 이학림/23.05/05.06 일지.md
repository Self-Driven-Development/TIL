# 학교 강의(딥러닝)
___
## 딥러닝
### DL 모델의 성능평가 - 에러
human level performance: 사람이 수동적으로 판단했을 때의 성능 
Bayes optimal error: 이상적인 에러의 최적값(가장 작은 값)

⇒ Bayes optimal error를 구해낼 방법이 있을까? → 없다! 
→ **Bayes optimal error ≈ human level performance**

딥러닝 학습을 통해서 DL 모델이 인간 수준의 성능까지 올라오도록 에러를 줄여나가는 것이 학습의 목표다.
___
### 인간 수준 성능까지 올리기 위해서
- 인간은 맞추지만 AI는 맞추지 못하는 데이터를 모으기
- 데이터의 공통된 특성을 통해 통찰 얻어내기
- 해당 특성을 고려해서 labeled data 설정하기
- **bias**, ~~variance~~ 수정하기

bias: training set error와 bayes optimal error와의 차이
___
### human level performance 정의
case) 의학 이미지를 분류하는 AI 모델을 학습시키고자 한다. 
이 때, '인간의 수준'이란 일반인, 의대생, 전문의 등의 인간집단 중 어떤 집단을 human level이라고 볼까?
Bayes optimal error의 추정치로서 human level performance를 쓰기 때문에, 
가장 오차가 작은 전문의 집단을 human level로 생각하는게 좋다.

if) 답이 정해져있지 않은 분야에 대해선 어떻게 해야할까?
예를들어 사람의 얼굴이 얼마나 예쁜지 평가하는 AI모델이 있다고 하자. 점수에 대한 기준이 객관적이지 않다. 이렇게 답이 정해져있지 않은 분야에 대해 평가할 때는 어떻게 해야하는지?
문제의 원인: 객관적인 답이 없으므로 (답-결과값)으로 도출해야 할 오차를 정의하기 힘들다.
___
### Error 분석
: 가능한 에러 - 잘못된 학습

공통적 특성으로 나타나는 문제점을 적어서 통계를 내서 문제가 뭔지 확인한다. (ex:고양이과 동물, 과한 필터, 반만 잘린 이미지 등)
___
### Incorrected labeled data
: 가능한 에러 - 인간의 실수
인간의 실수로 데이터 라벨링을 할 때 잘못 라벨링한 데이터를 사용하는 경우.(랜덤하게 생긴 에러면 문제가 안되는 수준의 노이즈로 ML 시스템에 문제가 되진 않는다.)
___
### Data mismatch problem
: 가능한 에러 - Dev, Test set과 Real data의 distribution이 일치하지 않음
ex: 모바일의 저품질 음성데이터를 서비스에서 다룰텐데, 학습할 때 쓰는 데이터가 너무 고품질인 경우

문제: match하는 데이터만 사용하기엔 데이터량이 충분하지 않아서 학습에 문제가 생길 수 있다.
해결: mismatch 데이터 또한 사용, 대신 Dev/Test set은 match 데이터로 구성
⇒ Training set과 Dev set 사이의 에러 차이가 클 때, variance의 문제인지 data mismatch의 문제인지 확인하기 힘들다.
___
### training dev set
: 구성 자체는 training set과 동일 = mismatch 데이터 또한 사용 && 학습에는 관여하지 않음

문제: variance의 문제인지 data mismatch의 문제인지 확인하기 힘들다.
해결: training dev set을 만들어서 다른 set의 에러와 비교한다.

dev set과 공통점: 학습에 관여하지 않음
dev set과 차이점: mismatch 데이터가 포함됨
⇒ 비교시 data mismatch problem 확인가능

training set과의 공통점: mismatch 데이터가 포함됨
training set과의 차이점: 학습에 관여하지 않음
⇒ 비교시 variance를 확인할 수 있음
___
### Data synthesis
: 데이터를 인위적으로 가공해서 match data화 해주는 데이터 전처리 과정
⇒ data mismatch problem 해결에 도움, 오버피팅에 주의
___
### mismatch에 대한 수동적 이해
training과 dev를 분석해보며 어떻게 distribution이 다른지 확인하고 매뉴얼하게 특성에 대한 전처리를 해준다.
___
### transfer learning
전이학습: 하나의 task의 NN를 다른 task에도 활용하는 것 → 모델이 확장성을 가짐

원리: NN의 단계의 의미를 생각해볼 때, 중복되는 단계가 있다.
ex: low level(경계선, 곡률) → medium level(창문, 바퀴) → Final(승용차) 
⇒ Final이 승용차가 아닌 트럭일 때, 중간 계층까지는 계층이 하는 일이 겹친다.
⇒ Final이 고양이일 때에도 low level 까지는 하는 일이 겹친다.

활용: 가지고 있는 데이터의 양이 불충분할 때, 비슷한 task의 NN 모델을 가져와서 마지막 계층만 현재 데이터에 맞게 변경해서 사용해도 높은 성능을 기대할 수 있다.

___
### multi task learning
: 한 데이터에서 여러 독립적인 결론을 내려야하는 경우
ex: 자율주행차 카메라의 데이터에서 '사람'이 있는지, '신호등'이 있는지, '차선'이 있는지 등을 한 화면에서 동시에 파악해야 함

활용: 데이터 개별적인 학습보단 multi task를 사용함
원리: 데이터들의 유사성(시각적 데이터) ⇒ transfer learning의 원리로 중복되는 NN단계가 있다
사물별로 개별적 학습이 아닌 전체 학습을 사용 ⇒ 충분한 training set을 확보해서 신뢰성을 높일 수 있다(low-level 단계에서)
___
### step by step learning
: 인간의 가이드라인을 따라 처리 과정을 단순화하는 방법

ex: 강아지의 암수를 구별하는 프로그램의 처리과정: 성기를 찾는다 → 성기 이미지만 crop한다 → 모양을 확인해서 암수를 구별한다


___
### end to end learning
: 학습시 raw input → output 과정에서 중간단계에 인간의 가이드라인은 쓰이지 않는다
\* input, output이 라벨링된다는 점에서 unsupervised learning은 아님

ex: 강아지의 암수를 구별하는 프로그램의 처리과정: 강아지 데이터를 넣는다 → 암수를 구별한다.

활용: NN의 중간과정에서 관련된 정보들을 매핑할 때 필요한 복잡성을 학습을 통해 해결할 수 있을만큼 충분한 데이터가 주어져야한다.
